{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2: Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = None\n",
    "\n",
    "with open('./../data/data.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /home/wiedzmin/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "# Download Corpora -> brown webtext words stopwords\n",
    "# Download Models -> punkt averaged_perceptron_tagger maxent_ne_chunker vader_lexicon wordnet tagsets\n",
    "nltk.download([\"brown\",\"webtext\", \"words\", \"stopwords\"] )\n",
    "nltk.download([\"punkt\", \"averaged_perceptron_tagger\", \"maxent_ne_chunker\", \"vader_lexicon\", \"wordnet\", \"tagsets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tokenCounts(tokens):\n",
    "    counts = Counter(tokens)\n",
    "    sortedCounts = sorted(counts.items(), key=lambda count:count[1], reverse=True)\n",
    "    return sortedCounts\n",
    "\n",
    "def listCounts(text, lst):\n",
    "    res = []\n",
    "    for item in lst:\n",
    "        item = item + (text.count(item[0]),)\n",
    "        item = [item[0], item[1], item[2]]\n",
    "        res.append(item)\n",
    "    res = sorted(res, key=lambda item: item[2], reverse=True)\n",
    "    return res\n",
    "\n",
    "def dictCounts(text, d):\n",
    "    items = d.items()\n",
    "    res = []\n",
    "    for item in items:\n",
    "        item = item + (text.count(item[0]),)\n",
    "        item = [item[0], item[1], item[2]]\n",
    "        res.append(item)\n",
    "    res = sorted(res, key=lambda item: item[2], reverse=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words total: 12728\n",
      "[(',', 714), ('the', 640), ('.', 533), ('of', 332), ('to', 330), ('and', 268), ('in', 218), ('a', 207), ('that', 149), ('is', 142), (\"'s\", 110), (\"''\", 97), ('are', 93), ('it', 93), ('``', 92), ('for', 90), ('says', 84), ('be', 73), ('as', 72), ('on', 71)]\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "print('Words total: {}'.format(len(tokens)))\n",
    "print(tokenCounts(tokens)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter punctation and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered words cnt: 6698\n",
      "[(\"'s\", 110), ('says', 84), ('The', 71), ('geothermal', 41), ('Ireland', 36), ('sargassum', 36), ('land', 33), ('ground', 32), ('In', 31), ('years', 28), ('Halligen', 27), ('steam', 26), ('also', 26), ('permafrost', 26), ('But', 24), ('Olkaria', 24), ('could', 24), ('one', 23), ('It', 23), (\"n't\", 22), ('water', 22), ('would', 21), ('people', 20), ('sea', 20), ('climate', 19), ('heat', 18), ('power', 18), ('We', 18), ('energy', 17), ('much', 17)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "def filterTokens(t):\n",
    "    # Filter custom special characters from text\n",
    "    extra_punctuation = punctuation + \"–''``’“\"\n",
    "    stops = stopwords.words('english')\n",
    "    filtered_tokens = [token for token in t if token not in extra_punctuation]\n",
    "    filtered_tokens = [token for token in filtered_tokens if token not in stops]\n",
    "    return filtered_tokens\n",
    "\n",
    "filtered_tokens = filterTokens(tokens)\n",
    "print('Filtered words cnt: {}'.format(len(filtered_tokens)))\n",
    "print(tokenCounts(filtered_tokens)[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus.reader.wordnet import NOUN,VERB\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# lemmas = {token:lemmatizer.lemmatize(token, pos=VERB) for token in filtered_tokens}\n",
    "# print('Lemmas count: {}'.format(len(lemmas)))\n",
    "\n",
    "# tf = {}\n",
    "\n",
    "# for key, val in lemmas.items():\n",
    "#     print([key, val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results total: 6698\n",
      "Top 50 results:\n",
      "[\"'s\", 'POS', 110]\n",
      "[\"'s\", 'POS', 110]\n",
      "[\"'s\", 'POS', 110]\n",
      "['In', 'IN', 43]\n",
      "['steam', 'NN', 28]\n",
      "['road', 'NN', 22]\n",
      "['energy', 'NN', 18]\n",
      "['see', 'VB', 18]\n",
      "['Kenya', 'NNP', 17]\n",
      "['past', 'IN', 13]\n",
      "['region', 'NN', 12]\n",
      "['Africa', 'NNP', 7]\n",
      "['tectonic', 'JJ', 7]\n",
      "['sometimes', 'RB', 7]\n",
      "['clean', 'VBP', 6]\n",
      "['Hell', 'NNP', 6]\n",
      "['National', 'NNP', 6]\n",
      "['Rift', 'NNP', 5]\n",
      "['apart', 'RB', 5]\n",
      "['Gate', 'NNP', 5]\n",
      "['East', 'NNP', 4]\n",
      "['Great', 'NNP', 4]\n",
      "['Valley', 'NNP', 4]\n",
      "['continent', 'JJ', 4]\n",
      "['along', 'IN', 4]\n",
      "['must', 'MD', 4]\n",
      "['releasing', 'VBG', 3]\n",
      "['winds', 'VBZ', 3]\n",
      "['volcanic', 'JJ', 2]\n",
      "['shifts', 'NNS', 2]\n",
      "['quantities', 'NNS', 2]\n",
      "['park', 'NN', 2]\n",
      "['giraffes', 'VBP', 2]\n",
      "[\"'ll\", 'MD', 2]\n",
      "['avoid', 'JJ', 2]\n",
      "['tearing', 'VBG', 1]\n",
      "['unimaginable', 'JJ', 1]\n",
      "['Drive', 'NNP', 1]\n",
      "['dusty', 'JJ', 1]\n",
      "['dirt', 'NN', 1]\n",
      "['zebra', 'NN', 1]\n",
      "['gazelles', 'NNS', 1]\n",
      "['plume', 'JJ', 1]\n",
      "['shooting', 'VBG', 1]\n",
      "['skyward', 'JJ', 1]\n",
      "['distance', 'NN', 1]\n",
      "['Vehicles', 'NNP', 1]\n",
      "['swerve', 'VB', 1]\n",
      "['running', 'VBG', 1]\n",
      "['warthogs', 'JJ', 1]\n"
     ]
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(filtered_tokens)\n",
    "print('Results total: {}'.format(len(tagged)))\n",
    "print('Top 50 results:')\n",
    "# print(listCounts(text, tagged[:50]))\n",
    "for item in listCounts(text, tagged[:50]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER with entity classification (using nltk.ne_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary results total: 179\n",
      "Top 50 binary results:\n",
      "['Ireland', 'NE', 36]\n",
      "['Hallig', 'NE', 32]\n",
      "['Halligen', 'NE', 27]\n",
      "['Olkaria', 'NE', 24]\n",
      "['Kenya', 'NE', 17]\n",
      "['Earth', 'NE', 13]\n",
      "['Atlantic', 'NE', 12]\n",
      "['German', 'NE', 11]\n",
      "['Newson', 'NE', 10]\n",
      "['Karingithi', 'NE', 9]\n",
      "['Daltun', 'NE', 9]\n",
      "['Hooge', 'NE', 9]\n",
      "['Mexico', 'NE', 9]\n",
      "['Mwangi', 'NE', 8]\n",
      "['County', 'NE', 8]\n",
      "['Germany', 'NE', 8]\n",
      "['Nordstrandischmoor', 'NE', 8]\n",
      "['Africa', 'NE', 7]\n",
      "['Hell', 'NE', 6]\n",
      "['Maasai', 'NE', 6]\n",
      "['Iceland', 'NE', 6]\n",
      "['Tibet', 'NE', 6]\n",
      "['Arctic', 'NE', 6]\n",
      "['Doré', 'NE', 6]\n",
      "['Irish', 'NE', 6]\n",
      "['North Sea', 'NE', 6]\n",
      "['Deicke', 'NE', 6]\n",
      "['Morrison', 'NE', 6]\n",
      "['Olkaria V', 'NE', 5]\n",
      "['CO2', 'NE', 5]\n",
      "['Northern Ireland', 'NE', 5]\n",
      "['Fogarty', 'NE', 5]\n",
      "['Rösner', 'NE', 5]\n",
      "['Caribbean', 'NE', 5]\n",
      "['Wang', 'NE', 5]\n",
      "['Olkaria VI', 'NE', 4]\n",
      "['KenGen', 'NE', 4]\n",
      "['Geothermal', 'NE', 4]\n",
      "['Rift Valley', 'NE', 4]\n",
      "['Nyaga', 'NE', 4]\n",
      "['Canada', 'NE', 4]\n",
      "['Highway', 'NE', 4]\n",
      "['Hansen', 'NE', 4]\n",
      "['Wadden Sea', 'NE', 4]\n",
      "['Gröde', 'NE', 4]\n",
      "['East Africa', 'NE', 3]\n",
      "['Great Rift Valley', 'NE', 3]\n",
      "['Anna Mwangi', 'NE', 3]\n",
      "['Suswa', 'NE', 3]\n",
      "['Sempui', 'NE', 3]\n",
      "Results total: 213\n",
      "Top 50 results:\n",
      "['Ireland', 'GPE', 36]\n",
      "['Hallig', 'PERSON', 32]\n",
      "['Halligen', 'PERSON', 27]\n",
      "['Olkaria', 'GPE', 24]\n",
      "['Kenya', 'PERSON', 17]\n",
      "['Earth', 'PERSON', 13]\n",
      "['Atlantic', 'ORGANIZATION', 12]\n",
      "['German', 'GPE', 11]\n",
      "['Newson', 'ORGANIZATION', 10]\n",
      "['Karingithi', 'PERSON', 9]\n",
      "['Mexico', 'GPE', 9]\n",
      "['Daltun', 'PERSON', 9]\n",
      "['Hooge', 'PERSON', 9]\n",
      "['Mwangi', 'PERSON', 8]\n",
      "['All', 'PERSON', 8]\n",
      "['Germany', 'GPE', 8]\n",
      "['Nordstrandischmoor', 'GPE', 8]\n",
      "['Africa', 'PERSON', 7]\n",
      "['Reid', 'PERSON', 7]\n",
      "['Hell', 'PERSON', 6]\n",
      "['Maasai', 'PERSON', 6]\n",
      "['Iceland', 'GPE', 6]\n",
      "['Arctic', 'ORGANIZATION', 6]\n",
      "['Doré', 'PERSON', 6]\n",
      "['Irish', 'GPE', 6]\n",
      "['North Sea', 'LOCATION', 6]\n",
      "['Deicke', 'PERSON', 6]\n",
      "['Allen', 'PERSON', 6]\n",
      "['Morrison', 'PERSON', 6]\n",
      "['Gate', 'ORGANIZATION', 5]\n",
      "['Olkaria V', 'PERSON', 5]\n",
      "['CO2', 'ORGANIZATION', 5]\n",
      "['High', 'ORGANIZATION', 5]\n",
      "['Northern Ireland', 'GPE', 5]\n",
      "['Fogarty', 'PERSON', 5]\n",
      "['Rösner', 'PERSON', 5]\n",
      "['Caribbean', 'LOCATION', 5]\n",
      "['Wang', 'PERSON', 5]\n",
      "['Olkaria VI', 'PERSON', 4]\n",
      "['KenGen', 'ORGANIZATION', 4]\n",
      "['Geothermal', 'ORGANIZATION', 4]\n",
      "['Rift Valley', 'PERSON', 4]\n",
      "['Nyaga', 'PERSON', 4]\n",
      "['Canada', 'GPE', 4]\n",
      "['Highway', 'PERSON', 4]\n",
      "['Hansen', 'PERSON', 4]\n",
      "['Wadden Sea', 'PERSON', 4]\n",
      "['Gröde', 'GPE', 4]\n",
      "['East Africa', 'PERSON', 3]\n",
      "['Great Rift Valley', 'PERSON', 3]\n"
     ]
    }
   ],
   "source": [
    "ne_chunked_binary = nltk.ne_chunk(tagged, binary=True)\n",
    "ne_chunked = nltk.ne_chunk(tagged, binary=False)\n",
    "\n",
    "def extractEntities(ne_chunked):\n",
    "    data = {}\n",
    "    for entity in ne_chunked:\n",
    "        if isinstance(entity, nltk.tree.Tree):\n",
    "            text = \" \".join([word for word, tag in entity.leaves()])\n",
    "            ent = entity.label()\n",
    "            data[text] = ent\n",
    "        else:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "ne_binary = extractEntities(ne_chunked_binary)\n",
    "ne_binary_cnts = dictCounts(text, ne_binary)\n",
    "print('Binary results total: {}'.format(len(ne_binary_cnts)))\n",
    "print('Top 50 binary results:')\n",
    "for item in ne_binary_cnts[:50]:\n",
    "    print(item)\n",
    "\n",
    "ne = extractEntities(ne_chunked)\n",
    "ne_cnts = dictCounts(text, ne)\n",
    "print('Results total: {}'.format(len(ne_cnts)))\n",
    "print('Top 50 results:')\n",
    "for item in ne_cnts[:50]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER with custom patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results total: 296\n",
      "Top 50 results:\n",
      "['Ireland', 'NP', 36]\n",
      "['Hallig', 'NP', 32]\n",
      "['Halligen', 'NP', 27]\n",
      "['Olkaria', 'NP', 24]\n",
      "['Kenya', 'NP', 17]\n",
      "['As', 'NP', 17]\n",
      "['Earth', 'NP', 13]\n",
      "['Atlantic', 'NP', 12]\n",
      "['Newson', 'NP', 10]\n",
      "['Hartwig-Kruse', 'NP', 10]\n",
      "['Karingithi', 'NP', 9]\n",
      "['Daltun', 'NP', 9]\n",
      "['Hooge', 'NP', 9]\n",
      "['Mexico', 'NP', 9]\n",
      "['Mwangi', 'NP', 8]\n",
      "['All', 'NP', 8]\n",
      "['Germany', 'NP', 8]\n",
      "['Nordstrandischmoor', 'NP', 8]\n",
      "['Africa', 'NP', 7]\n",
      "['Reid', 'NP', 7]\n",
      "['Hell', 'NP', 6]\n",
      "['Maasai', 'NP', 6]\n",
      "['Iceland', 'NP', 6]\n",
      "['Arctic', 'NP', 6]\n",
      "['Doré', 'NP', 6]\n",
      "['Republic', 'NP', 6]\n",
      "['North Sea', 'NP', 6]\n",
      "['Deicke', 'NP', 6]\n",
      "['Allen', 'NP', 6]\n",
      "['Morrison', 'NP', 6]\n",
      "['Gate', 'NP', 5]\n",
      "['Olkaria V', 'NP', 5]\n",
      "['CO2', 'NP', 5]\n",
      "['Northern Ireland', 'NP', 5]\n",
      "['Fogarty', 'NP', 5]\n",
      "[\"O'Connell\", 'NP', 5]\n",
      "['Rösner', 'NP', 5]\n",
      "['Caribbean', 'NP', 5]\n",
      "['Wang', 'NP', 5]\n",
      "['Olkaria VI', 'NP', 4]\n",
      "['KenGen', 'NP', 4]\n",
      "['Geothermal', 'NP', 4]\n",
      "['Rift Valley', 'NP', 4]\n",
      "['Nyaga', 'NP', 4]\n",
      "['Canada', 'NP', 4]\n",
      "['Hansen', 'NP', 4]\n",
      "['Europe', 'NP', 4]\n",
      "['Wadden Sea', 'NP', 4]\n",
      "['Gröde', 'NP', 4]\n",
      "['East Africa', 'NP', 3]\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NNP|NNPS>+}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "ne_custom_tmp = extractEntities(cp.parse(tagged))\n",
    "ne_custom = {}\n",
    "for entity, phr in ne_custom_tmp.items():\n",
    "    if len(entity) > 1:\n",
    "        ne_custom[entity] = phr \n",
    "print('Results total: {}'.format(len(ne_custom)))\n",
    "print('Top 50 results:')\n",
    "ne_custom_cnts = dictCounts(text, ne_custom)\n",
    "for item in ne_custom_cnts[:50]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom entity classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER using nltk.ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ireland', 'GPE', 36], 'piece of subcontinental land']\n",
      "[['Hallig', 'PERSON', 32], 'small islands without protective dikes']\n",
      "[['Halligen', 'PERSON', 27], 'small islands without protective dikes']\n",
      "[['Olkaria', 'GPE', 24], 'region']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wiedzmin/Dokumenty/NI-DDW/homeworks/pondepe1/02/src/ddw-hw-2/lib/python3.8/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/wiedzmin/Dokumenty/NI-DDW/homeworks/pondepe1/02/src/ddw-hw-2/lib/python3.8/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html5lib\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Kenya', 'PERSON', 17], 'generic']\n",
      "[['Earth', 'PERSON', 13], 'generic']\n",
      "[['Atlantic', 'ORGANIZATION', 12], 'second-largest of the world']\n",
      "[['German', 'GPE', 11], 'country at the intersection']\n",
      "[['Newson', 'ORGANIZATION', 10], 'generic']\n",
      "[['Karingithi', 'PERSON', 9], 'generic']\n",
      "[['Mexico', 'GPE', 9], 'country in the southern portion']\n",
      "[['Daltun', 'PERSON', 9], 'Goidelic language of the Insular Celtic branch']\n",
      "[['Hooge', 'PERSON', 9], 'generic']\n",
      "[['Mwangi', 'PERSON', 8], 'Kenyan photojournalist']\n",
      "[['All', 'PERSON', 8], 'sorosilicate group of minerals']\n",
      "[['Germany', 'GPE', 8], 'country at the intersection']\n",
      "[['Nordstrandischmoor', 'GPE', 8], 'generic']\n",
      "[['Africa', 'PERSON', 7], 'country']\n",
      "[['Reid', 'PERSON', 7], 'technique wherein']\n",
      "[['Hell', 'PERSON', 6], 'generic']\n",
      "[['Maasai', 'PERSON', 6], 'Nilotic ethnic group']\n",
      "[['Iceland', 'GPE', 6], 'island in the North Atlantic']\n",
      "[['Arctic', 'ORGANIZATION', 6], 'generic']\n",
      "[['Doré', 'PERSON', 6], 'generic']\n",
      "[['Irish', 'GPE', 6], 'islands of Ireland and Great Britain']\n",
      "[['North Sea', 'LOCATION', 6], 'sea of the Atlantic Ocean']\n",
      "[['Deicke', 'PERSON', 6], 'generic']\n",
      "[['Allen', 'PERSON', 6], 'English actor']\n",
      "[['Morrison', 'PERSON', 6], 'fourth largest chain of supermarkets']\n",
      "[['Gate', 'ORGANIZATION', 5], 'structured form of play']\n",
      "[['Olkaria V', 'PERSON', 5], 'power station in Kenya']\n",
      "[['CO2', 'ORGANIZATION', 5], 'colorless gas with a density']\n",
      "[['High', 'ORGANIZATION', 5], 'measure of vertical distance']\n",
      "[['Northern Ireland', 'GPE', 5], 'generic']\n",
      "[['Fogarty', 'PERSON', 5], 'surname of Irish origin']\n",
      "[['Rösner', 'PERSON', 5], 'hostage-taking crisis']\n",
      "[['Caribbean', 'LOCATION', 5], 'region of the Americas']\n",
      "[['Wang', 'PERSON', 5], 'type of fin']\n",
      "[['Olkaria VI', 'PERSON', 4], 'geothermal power station in Kenya']\n",
      "[['KenGen', 'ORGANIZATION', 4], 'parastatal company']\n",
      "[['Geothermal', 'ORGANIZATION', 4], 'thermal energy']\n",
      "[['Rift Valley', 'PERSON', 4], 'linear shaped lowland between several highlands']\n",
      "[['Nyaga', 'PERSON', 4], 'generic']\n",
      "[['Canada', 'GPE', 4], 'country in the northern part']\n",
      "[['Highway', 'PERSON', 4], 'public or private road']\n",
      "[['Hansen', 'PERSON', 4], 'American beverage company']\n",
      "[['Wadden Sea', 'PERSON', 4], 'intertidal zone in the southeastern part']\n",
      "[['Gröde', 'GPE', 4], 'municipality in the district']\n",
      "[['East Africa', 'PERSON', 3], 'eastern subregion of the African continent']\n",
      "[['Great Rift Valley', 'PERSON', 3], 'series of contiguous geographic trenches']\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def nearestTerm(term, options):\n",
    "    maxRatio = -1.0\n",
    "    nearest = options[0]\n",
    "    for opt in options:\n",
    "        # Use longest contiguous matching subsequence\n",
    "        ratio = SequenceMatcher(None, term, opt).ratio()\n",
    "        if ratio > maxRatio:\n",
    "            maxRatio = ratio\n",
    "            nearest = opt\n",
    "    return nearest\n",
    "\n",
    "def classFromSummary(summary, generic):\n",
    "    first_sent = nltk.sent_tokenize(summary)[0]\n",
    "    first_sent_tokens = nltk.word_tokenize(first_sent)\n",
    "    first_sent_tagged = nltk.pos_tag(first_sent_tokens)\n",
    "#     print(first_sent)\n",
    "#     print(first_sent_tagged)\n",
    "    grammar = \"NP: {<VBZ|VBP|VBD><DT><JJ|JJR|JJS|CC|NNP|IN|,>*<NN|NNS>+(<IN><DT>?<JJ|JJR|JJS|CC|NNP|IN|,>*<NN|NNS|NNP|NNPS>+)?}\"\n",
    "    c = nltk.RegexpParser(grammar)\n",
    "    classification = extractEntities(c.parse(first_sent_tagged))\n",
    "    if len(classification) < 1:\n",
    "        grammar = \"NP: {<VBZ|VBP|VBD><DT>?<JJ|JJR|JJS|CC|NNP|IN|,>*<NN|NNS>+(<IN><DT>?<JJ|JJR|JJS|CC|NNP|IN|,>*<NN|NNS|NNP|NNPS>+)?}\"\n",
    "        c = nltk.RegexpParser(grammar)\n",
    "        classification = extractEntities(c.parse(first_sent_tagged))\n",
    "        if len(classification) < 1:\n",
    "            return generic\n",
    "    classification = next(iter(classification))\n",
    "#     print(classification)\n",
    "    classification_tagged = nltk.pos_tag(nltk.word_tokenize(classification))\n",
    "    grammar = \"NP: {<JJ|JJR|JJS|CC|NNP|IN|,>*<NN|NNS>+(<IN><DT>?<JJ|JJR|JJS|CC|NNP|IN|,>*<NN|NNS|NNP|NNPS>+)?}\"\n",
    "    c = nltk.RegexpParser(grammar)\n",
    "    classification = extractEntities(c.parse(classification_tagged))\n",
    "    classification = next(iter(classification))\n",
    "    return classification\n",
    "\n",
    "def wikipediaClassification(entity):\n",
    "    generic_class = 'generic'\n",
    "    try:\n",
    "        results = wikipedia.search(entity)\n",
    "        if len(results) < 1:\n",
    "            return generic_class\n",
    "        page = wikipedia.page(results[0])\n",
    "        return classFromSummary(page.summary, generic_class)\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        # Handle ambiguous search result - find nearest option\n",
    "        nearest = nearestTerm(entity, e.options)\n",
    "        try:\n",
    "            page = wikipedia.page(nearest)\n",
    "            return classFromSummary(page.summary, generic_class)\n",
    "        except (wikipedia.DisambiguationError, wikipedia.PageError):\n",
    "            # In case of multiple ambiguousity, return generic classification\n",
    "            return generic_class\n",
    "    except wikipedia.PageError:\n",
    "        return generic_class\n",
    "\n",
    "ne_wikipedia_classified = []\n",
    "    \n",
    "for entity in ne_cnts[:50]:\n",
    "    classification = wikipediaClassification(entity[0])\n",
    "    ne_wikipedia_classified.append([entity, classification])\n",
    "    print([entity, classification])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER with custom patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ireland', 'NP', 36], 'piece of subcontinental land']\n",
      "[['Hallig', 'NP', 32], 'small islands without protective dikes']\n",
      "[['Halligen', 'NP', 27], 'small islands without protective dikes']\n",
      "[['Olkaria', 'NP', 24], 'region']\n",
      "[['Kenya', 'NP', 17], 'generic']\n",
      "[['As', 'NP', 17], 'first letter']\n",
      "[['Earth', 'NP', 13], 'generic']\n",
      "[['Atlantic', 'NP', 12], 'second-largest of the world']\n",
      "[['Newson', 'NP', 10], 'generic']\n",
      "[['Hartwig-Kruse', 'NP', 10], 'German politician for the populist Alternative for Germany']\n",
      "[['Karingithi', 'NP', 9], 'generic']\n",
      "[['Daltun', 'NP', 9], 'Goidelic language of the Insular Celtic branch']\n",
      "[['Hooge', 'NP', 9], 'generic']\n",
      "[['Mexico', 'NP', 9], 'country in the southern portion']\n",
      "[['Mwangi', 'NP', 8], 'Kenyan photojournalist']\n",
      "[['All', 'NP', 8], 'sorosilicate group of minerals']\n",
      "[['Germany', 'NP', 8], 'country at the intersection']\n",
      "[['Nordstrandischmoor', 'NP', 8], 'generic']\n",
      "[['Africa', 'NP', 7], 'country']\n",
      "[['Reid', 'NP', 7], 'technique wherein']\n",
      "[['Hell', 'NP', 6], 'generic']\n",
      "[['Maasai', 'NP', 6], 'Nilotic ethnic group']\n",
      "[['Iceland', 'NP', 6], 'island in the North Atlantic']\n",
      "[['Arctic', 'NP', 6], 'generic']\n",
      "[['Doré', 'NP', 6], 'generic']\n",
      "[['Republic', 'NP', 6], 'form of government']\n",
      "[['North Sea', 'NP', 6], 'sea of the Atlantic Ocean']\n",
      "[['Deicke', 'NP', 6], 'generic']\n",
      "[['Allen', 'NP', 6], 'English actor']\n",
      "[['Morrison', 'NP', 6], 'fourth largest chain of supermarkets']\n",
      "[['Gate', 'NP', 5], 'structured form of play']\n",
      "[['Olkaria V', 'NP', 5], 'power station in Kenya']\n",
      "[['CO2', 'NP', 5], 'colorless gas with a density']\n",
      "[['Northern Ireland', 'NP', 5], 'generic']\n",
      "[['Fogarty', 'NP', 5], 'surname of Irish origin']\n",
      "[[\"O'Connell\", 'NP', 5], 'American singer-songwriter']\n",
      "[['Rösner', 'NP', 5], 'hostage-taking crisis']\n",
      "[['Caribbean', 'NP', 5], 'region of the Americas']\n",
      "[['Wang', 'NP', 5], 'type of fin']\n",
      "[['Olkaria VI', 'NP', 4], 'geothermal power station in Kenya']\n",
      "[['KenGen', 'NP', 4], 'parastatal company']\n",
      "[['Geothermal', 'NP', 4], 'thermal energy']\n",
      "[['Rift Valley', 'NP', 4], 'linear shaped lowland between several highlands']\n",
      "[['Nyaga', 'NP', 4], 'generic']\n",
      "[['Canada', 'NP', 4], 'country in the northern part']\n",
      "[['Hansen', 'NP', 4], 'American beverage company']\n",
      "[['Europe', 'NP', 4], 'continent']\n",
      "[['Wadden Sea', 'NP', 4], 'intertidal zone in the southeastern part']\n",
      "[['Gröde', 'NP', 4], 'municipality in the district']\n",
      "[['East Africa', 'NP', 3], 'eastern subregion of the African continent']\n"
     ]
    }
   ],
   "source": [
    "ne_custom_wikipedia_classified = []\n",
    "for entity in ne_custom_cnts[:50]:\n",
    "    classification = wikipediaClassification(entity[0])\n",
    "    ne_custom_wikipedia_classified.append([entity, classification])\n",
    "    print([entity, classification])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|['Ireland', 'GPE']|['Ireland', 'piece of subcontinental land']|['Ireland', 'NP', 'piece of subcontinental land']\n",
      "\n",
      "|['Hallig', 'PERSON']|['Hallig', 'small islands without protective dikes']|['Hallig', 'NP', 'small islands without protective dikes']\n",
      "\n",
      "|['Halligen', 'PERSON']|['Halligen', 'small islands without protective dikes']|['Halligen', 'NP', 'small islands without protective dikes']\n",
      "\n",
      "|['Olkaria', 'GPE']|['Olkaria', 'region']|['Olkaria', 'NP', 'region']\n",
      "\n",
      "|['Kenya', 'PERSON']|['Kenya', 'generic']|['Kenya', 'NP', 'generic']\n",
      "\n",
      "|['Earth', 'PERSON']|['Earth', 'generic']|['As', 'NP', 'first letter']\n",
      "\n",
      "|['Atlantic', 'ORGANIZATION']|['Atlantic', 'second-largest of the world']|['Earth', 'NP', 'generic']\n",
      "\n",
      "|['German', 'GPE']|['German', 'country at the intersection']|['Atlantic', 'NP', 'second-largest of the world']\n",
      "\n",
      "|['Newson', 'ORGANIZATION']|['Newson', 'generic']|['Newson', 'NP', 'generic']\n",
      "\n",
      "|['Karingithi', 'PERSON']|['Karingithi', 'generic']|['Hartwig-Kruse', 'NP', 'German politician for the populist Alternative for Germany']\n",
      "\n",
      "|['Mexico', 'GPE']|['Mexico', 'country in the southern portion']|['Karingithi', 'NP', 'generic']\n",
      "\n",
      "|['Daltun', 'PERSON']|['Daltun', 'Goidelic language of the Insular Celtic branch']|['Daltun', 'NP', 'Goidelic language of the Insular Celtic branch']\n",
      "\n",
      "|['Hooge', 'PERSON']|['Hooge', 'generic']|['Hooge', 'NP', 'generic']\n",
      "\n",
      "|['Mwangi', 'PERSON']|['Mwangi', 'Kenyan photojournalist']|['Mexico', 'NP', 'country in the southern portion']\n",
      "\n",
      "|['All', 'PERSON']|['All', 'sorosilicate group of minerals']|['Mwangi', 'NP', 'Kenyan photojournalist']\n",
      "\n",
      "|['Germany', 'GPE']|['Germany', 'country at the intersection']|['All', 'NP', 'sorosilicate group of minerals']\n",
      "\n",
      "|['Nordstrandischmoor', 'GPE']|['Nordstrandischmoor', 'generic']|['Germany', 'NP', 'country at the intersection']\n",
      "\n",
      "|['Africa', 'PERSON']|['Africa', 'country']|['Nordstrandischmoor', 'NP', 'generic']\n",
      "\n",
      "|['Reid', 'PERSON']|['Reid', 'technique wherein']|['Africa', 'NP', 'country']\n",
      "\n",
      "|['Hell', 'PERSON']|['Hell', 'generic']|['Reid', 'NP', 'technique wherein']\n",
      "\n",
      "|['Maasai', 'PERSON']|['Maasai', 'Nilotic ethnic group']|['Hell', 'NP', 'generic']\n",
      "\n",
      "|['Iceland', 'GPE']|['Iceland', 'island in the North Atlantic']|['Maasai', 'NP', 'Nilotic ethnic group']\n",
      "\n",
      "|['Arctic', 'ORGANIZATION']|['Arctic', 'generic']|['Iceland', 'NP', 'island in the North Atlantic']\n",
      "\n",
      "|['Doré', 'PERSON']|['Doré', 'generic']|['Arctic', 'NP', 'generic']\n",
      "\n",
      "|['Irish', 'GPE']|['Irish', 'islands of Ireland and Great Britain']|['Doré', 'NP', 'generic']\n",
      "\n",
      "|['North Sea', 'LOCATION']|['North Sea', 'sea of the Atlantic Ocean']|['Republic', 'NP', 'form of government']\n",
      "\n",
      "|['Deicke', 'PERSON']|['Deicke', 'generic']|['North Sea', 'NP', 'sea of the Atlantic Ocean']\n",
      "\n",
      "|['Allen', 'PERSON']|['Allen', 'English actor']|['Deicke', 'NP', 'generic']\n",
      "\n",
      "|['Morrison', 'PERSON']|['Morrison', 'fourth largest chain of supermarkets']|['Allen', 'NP', 'English actor']\n",
      "\n",
      "|['Gate', 'ORGANIZATION']|['Gate', 'structured form of play']|['Morrison', 'NP', 'fourth largest chain of supermarkets']\n",
      "\n",
      "|['Olkaria V', 'PERSON']|['Olkaria V', 'power station in Kenya']|['Gate', 'NP', 'structured form of play']\n",
      "\n",
      "|['CO2', 'ORGANIZATION']|['CO2', 'colorless gas with a density']|['Olkaria V', 'NP', 'power station in Kenya']\n",
      "\n",
      "|['High', 'ORGANIZATION']|['High', 'measure of vertical distance']|['CO2', 'NP', 'colorless gas with a density']\n",
      "\n",
      "|['Northern Ireland', 'GPE']|['Northern Ireland', 'generic']|['Northern Ireland', 'NP', 'generic']\n",
      "\n",
      "|['Fogarty', 'PERSON']|['Fogarty', 'surname of Irish origin']|['Fogarty', 'NP', 'surname of Irish origin']\n",
      "\n",
      "|['Rösner', 'PERSON']|['Rösner', 'hostage-taking crisis']|[\"O'Connell\", 'NP', 'American singer-songwriter']\n",
      "\n",
      "|['Caribbean', 'LOCATION']|['Caribbean', 'region of the Americas']|['Rösner', 'NP', 'hostage-taking crisis']\n",
      "\n",
      "|['Wang', 'PERSON']|['Wang', 'type of fin']|['Caribbean', 'NP', 'region of the Americas']\n",
      "\n",
      "|['Olkaria VI', 'PERSON']|['Olkaria VI', 'geothermal power station in Kenya']|['Wang', 'NP', 'type of fin']\n",
      "\n",
      "|['KenGen', 'ORGANIZATION']|['KenGen', 'parastatal company']|['Olkaria VI', 'NP', 'geothermal power station in Kenya']\n",
      "\n",
      "|['Geothermal', 'ORGANIZATION']|['Geothermal', 'thermal energy']|['KenGen', 'NP', 'parastatal company']\n",
      "\n",
      "|['Rift Valley', 'PERSON']|['Rift Valley', 'linear shaped lowland between several highlands']|['Geothermal', 'NP', 'thermal energy']\n",
      "\n",
      "|['Nyaga', 'PERSON']|['Nyaga', 'generic']|['Rift Valley', 'NP', 'linear shaped lowland between several highlands']\n",
      "\n",
      "|['Canada', 'GPE']|['Canada', 'country in the northern part']|['Nyaga', 'NP', 'generic']\n",
      "\n",
      "|['Highway', 'PERSON']|['Highway', 'public or private road']|['Canada', 'NP', 'country in the northern part']\n",
      "\n",
      "|['Hansen', 'PERSON']|['Hansen', 'American beverage company']|['Hansen', 'NP', 'American beverage company']\n",
      "\n",
      "|['Wadden Sea', 'PERSON']|['Wadden Sea', 'intertidal zone in the southeastern part']|['Europe', 'NP', 'continent']\n",
      "\n",
      "|['Gröde', 'GPE']|['Gröde', 'municipality in the district']|['Wadden Sea', 'NP', 'intertidal zone in the southeastern part']\n",
      "\n",
      "|['East Africa', 'PERSON']|['East Africa', 'eastern subregion of the African continent']|['Gröde', 'NP', 'municipality in the district']\n",
      "\n",
      "|['Great Rift Valley', 'PERSON']|['Great Rift Valley', 'series of contiguous geographic trenches']|['East Africa', 'NP', 'eastern subregion of the African continent']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print('|{}|{}|{}\\n'.format([ne_cnts[i][0], ne_cnts[i][1]], [ne_wikipedia_classified[i][0][0], ne_wikipedia_classified[i][1]], [ne_custom_wikipedia_classified[i][0][0], ne_custom_wikipedia_classified[i][0][1], ne_custom_wikipedia_classified[i][1]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
