{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Social Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "\n",
    "def print_dict(d, k=10):\n",
    "    for item in list(d.items())[:k]:\n",
    "        print(item)\n",
    "        \n",
    "def lists_overlap(l1, l2):\n",
    "    return bool(set(l1) & set(l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "casts = pd.read_csv('./../data/casts.csv', error_bad_lines = False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert „casts“ data to a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actor_type', 'movie', 'actor', 'role_type', 'role']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 10203/16610 [03:16<03:16, 32.64it/s]"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# Print casts CSV column headers\n",
    "print(casts.columns.tolist())\n",
    "\n",
    "# Group movies by actors\n",
    "movies_by_actor = casts.groupby('actor')['movie']\n",
    "# movies_by_actor = casts[casts['actor_type'] < 'AA90'].groupby('actor')['movie']\n",
    "movies_by_actor_dict = movies_by_actor.apply(list).to_dict()\n",
    "# print(len(movies_by_actor_dict))\n",
    "# print(movies_by_actor_dict['A.E. Matthews'])\n",
    "# print(movies_by_actor_dict)\n",
    "\n",
    "# Filter the supporting actor\n",
    "if 's a' in movies_by_actor_dict:\n",
    "    del movies_by_actor_dict['s a']\n",
    "\n",
    "# Filter numeric actor values\n",
    "# Using dictionary comprehension to find list\n",
    "# Get numeric actors\n",
    "delete = [key for key in movies_by_actor_dict if key.isnumeric()]\n",
    "\n",
    "# Delete the key\n",
    "for key in delete: del movies_by_actor_dict[key]\n",
    "        \n",
    "# Create the graph\n",
    "for actor in movies_by_actor_dict.keys():\n",
    "    G.add_node(actor)\n",
    "        \n",
    "# Test if two lists overlaps\n",
    "# print(bool(set(movies_by_actor_dict['A.E. Matthews']) & set(movies_by_actor_dict['David Tree'])))\n",
    "# print(bool(set(movies_by_actor_dict['A.E. Matthews']) & set(movies_by_actor_dict['Athene Seyler'])))\n",
    "\n",
    "for actor1, movies1 in tqdm(movies_by_actor_dict.items(), total=len(G.nodes())):\n",
    "    for actor2, movies2 in movies_by_actor_dict.items():\n",
    "        if actor1 != actor2 and lists_overlap(movies1, movies2):\n",
    "            G.add_edge(actor1, actor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset general statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_statistics(graph, visualize_components=False):\n",
    "    n = len(graph.nodes())\n",
    "    e = len(graph.edges())\n",
    "    print('Number of nodes: ', n)\n",
    "    print('Number of edges: ', e)\n",
    "    print('Density: ', e / (n*(n-1)/2))\n",
    "    components = list(nx.connected_components(graph))\n",
    "    if visualize_components:\n",
    "        pos = graphviz_layout(graph)\n",
    "        nx.draw(graph, pos, with_labels=False, node_size=10)\n",
    "    print('Number of components: ', len(components))\n",
    "    \n",
    "general_statistics(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centralities(graph, centralities, k):\n",
    "    for centrality in tqdm(centralities, total=len(centralities)):\n",
    "        print('Top {} players by {}:'.format(k, centrality.__name__))\n",
    "        c_dict = centrality(graph)\n",
    "        c_dict = dict(sorted(c_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "        for item in list(c_dict.items()):\n",
    "            graph.nodes[item[0]][centrality.__name__] = item[1]\n",
    "        print_dict(c_dict)\n",
    "        print('\\n')\n",
    "    return graph\n",
    "\n",
    "G = compute_centralities(G, [nx.degree_centrality, nx.closeness_centrality, nx.betweenness_centrality, nx.eigenvector_centrality], k)\n",
    "# G = compute_centralities(G, [nx.degree_centrality], k)\n",
    "# print(G.nodes['Humphrey Bogart'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = {node:cid+1 for cid,community in enumerate(nx.algorithms.community.k_clique_communities(G,59)) for node in community}\n",
    "print('Largest community has size of {} nodes:'.format(len(communities)))\n",
    "print_dict(communities, len(communities))\n",
    "print('\\n')\n",
    "\n",
    "communities = {node:cid+1 for cid,community in enumerate(nx.algorithms.community.k_clique_communities(G,35)) for node in community}\n",
    "print('Communities with at least 35 nodes:')\n",
    "print_dict(communities, len(communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kevin Bacon numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kevin_bacon_numbers(graph):\n",
    "    for a in graph.nodes():\n",
    "        try:\n",
    "            path = nx.shortest_path(graph,source=a,target='Kevin Bacon')\n",
    "            graph.nodes[a]['kevin_bacon_number'] = int(len(path)/2)\n",
    "        except nx.NetworkXNoPath:\n",
    "            graph.nodes[a]['kevin_bacon_number'] = len(graph.nodes())\n",
    "#         print('{0}: {1}'.format(a, graph.nodes[a]))\n",
    "    return graph\n",
    "\n",
    "print('Top {} actors with Kevin Bacon number:'.format(k))\n",
    "G = kevin_bacon_numbers(G)\n",
    "# print(G.nodes['Humphrey Bogart'])\n",
    "\n",
    "\n",
    "#=== Top k actors by Kevin Bacon number (including infinite KB number - actors wign non-existing path to KB)\n",
    "# Sort actors by Kevin Bacon number\n",
    "kevin_bacon_desc = dict(sorted(dict(G.nodes(data=True)).items(), key=lambda item: item[1]['kevin_bacon_number'], reverse=True))\n",
    "print_dict(kevin_bacon_desc)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#=== Top k actors by Kevin Bacon number (finite only)\n",
    "kevin_bacon_decs_fin = {}\n",
    "\n",
    "# Filter actors by finite Kevin Bacon number\n",
    "to_add = [key for key in kevin_bacon_desc if kevin_bacon_desc[key]['kevin_bacon_number'] is not math.inf]\n",
    "for key in to_add:\n",
    "    kevin_bacon_decs_fin[key] = kevin_bacon_desc[key]\n",
    "    \n",
    "print('Top {} actors with finite Kevin Bacon number:'.format(k))\n",
    "print_dict(kevin_bacon_decs_fin)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#=== Bottom k actors by Kevin Bacon number\n",
    "print('Bottom {} actors with finite Kevin Bacon number:'.format(k))\n",
    "kevin_bacon_asc_fin = dict(sorted(kevin_bacon_decs_fin.items(), key=lambda item: item[1]['kevin_bacon_number']))\n",
    "print_dict(kevin_bacon_asc_fin)\n",
    "print('\\n')\n",
    "\n",
    "#=== Average Kevin Bacon number (finite numbers only)\n",
    "sum = 0\n",
    "for item in kevin_bacon_asc_fin.items():\n",
    "    sum += item[1]['kevin_bacon_number']\n",
    "kv_avg = sum/len(kevin_bacon_asc_fin)\n",
    "print('Average Kevin Bacon number: {}'.format(kv_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save into GEXF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, './../results/actors_casts.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_casts_cnt = casts['movie'].value_counts().to_dict()\n",
    "print(len(movies_casts_cnt))\n",
    "# print(movies_casts_cnt)\n",
    "\n",
    "movies_reduced = list(k for (k, v) in movies_casts_cnt.items() if (v < 5))\n",
    "print(len(movies_reduced))\n",
    "# print(movies_reduced)\n",
    "\n",
    "movies_by_actor_reduced_dict = {}\n",
    "\n",
    "for key, val in movies_by_actor_dict.items():\n",
    "    if lists_overlap(val, movies_reduced):\n",
    "        movies_by_actor_reduced_dict[key] = val\n",
    "\n",
    "print(len(movies_by_actor_reduced_dict))\n",
    "# print(movies_by_actor_reduced_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct reduced graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "G_reduced = nx.Graph()\n",
    "\n",
    "for actor in movies_by_actor_reduced_dict.keys():\n",
    "    G_reduced.add_node(actor)\n",
    "\n",
    "for actor1, movies1 in tqdm(movies_by_actor_reduced_dict.items(), total=len(G_reduced.nodes())):\n",
    "    for actor2, movies2 in movies_by_actor_reduced_dict.items():\n",
    "        if actor1 != actor2 and lists_overlap(movies1, movies2):\n",
    "            G_reduced.add_edge(actor1, actor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced graph general statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_statistics(G_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_reduced = compute_centralities(G_reduced, [nx.degree_centrality, nx.closeness_centrality, nx.betweenness_centrality, nx.eigenvector_centrality], k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = {node:cid+1 for cid,community in enumerate(nx.algorithms.community.k_clique_communities(G_reduced,20)) for node in community}\n",
    "print('Communities with at least 20 nodes:')\n",
    "print_dict(communities, len(communities))\n",
    "\n",
    "for key, val in G_reduced.nodes().items():\n",
    "    if key in communities:\n",
    "        G_reduced.nodes[key]['community'] = communities[key]\n",
    "    else:\n",
    "        G_reduced.nodes[key]['community'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Kevin Bacon numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_reduced = kevin_bacon_numbers(G_reduced)\n",
    "print_dict(G_reduced.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save into GEFX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G_reduced, './../results/actors_casts_reduced.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G_reduced.nodes['Matthew Settle'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
